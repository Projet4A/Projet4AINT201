{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P4A_ML_com.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPtRVjgGbQzqCOH8KC6MS6J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Projet4A/Projet4AINT201/blob/Aurelien/P4A_Piotrowski/P4A_ML_com.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN34XbU9GuGe"
      },
      "source": [
        "# **Importations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGZKjHClGr1n"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.pipeline import make_pipeline\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "import xgboost as xgb\r\n",
        "from sklearn import svm\r\n",
        "from sklearn.compose import make_column_transformer\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.feature_selection import SelectKBest\r\n",
        "import seaborn as sns\r\n",
        "from sklearn.metrics import recall_score\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from sklearn.metrics import precision_score\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "import os\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision\r\n",
        "import pickle\r\n",
        "from xgboost import plot_importance\r\n",
        "from sklearn.inspection import permutation_importance\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from xgboost import plot_tree\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y-kyZn9G2Rb"
      },
      "source": [
        "# **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKSztLSTG_BG",
        "outputId": "af638dde-f81e-416a-d31c-e6a5a6bfb3b9"
      },
      "source": [
        "#Load data from the drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5F4ymCjHIPe"
      },
      "source": [
        "# **Traitement des données**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjjRqjTMHGxg"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Data/ClientA_Data_NC.csv')\r\n",
        "data.RPM.fillna(data.RPM.mean(),inplace=True)\r\n",
        "\r\n",
        "encodeur = LabelEncoder()\r\n",
        "Y=encodeur.fit_transform(data.FaultStatus)\r\n",
        "X=data.drop(['DateTime_x','Bearing_Location','Date','EquipmentID','SurveyDate','EquipmentName','AnalysisDate','FaultStatus','FaultName','Comment','Location','Analyst','AreaID','Route','EquipmentName'],axis=1)\r\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2, random_state=42)\r\n",
        "\r\n",
        "numerical_features = ['DataValue','RPM','Units']\r\n",
        "categorical_features = ['EquipmentClassification','Description_Area','Description_Equipment','MptID','Description_MeasPt','Description_APSet','Description_AnalParm','AreaName']\r\n",
        "\r\n",
        "numerical_pipeline = make_pipeline(StandardScaler())\r\n",
        "categorical_pipeline = make_pipeline(OneHotEncoder(categories='auto',sparse=False,handle_unknown = 'ignore'))\r\n",
        "\r\n",
        "transformer = make_column_transformer((numerical_pipeline, numerical_features),(categorical_pipeline,categorical_features))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IPJ08RtIFWU"
      },
      "source": [
        "# **Modèles Machine Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c691g0ufJm4C"
      },
      "source": [
        "# Project the data onto the 2 primary principal components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3g0lvpmJyRM"
      },
      "source": [
        "X_bis?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "m_j5t7XwIBJP",
        "outputId": "fd9f3281-2e3b-41ab-e360-4badb76d9b4e"
      },
      "source": [
        "pca = PCA(2)\r\n",
        "X_projected = pca.fit_transform(X_bis)\r\n",
        "\r\n",
        "x1 = X_projected[:, 0]\r\n",
        "x2 = X_projected[:, 1]\r\n",
        "\r\n",
        "fig = plt.figure()\r\n",
        "plt.scatter(x1, x2,\r\n",
        "        c=Y, alpha=0.8,\r\n",
        "        cmap='viridis')\r\n",
        "\r\n",
        "plt.xlabel('Principal Component 1')\r\n",
        "plt.ylabel('Principal Component 2')\r\n",
        "plt.colorbar()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-623345a90ffe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_projected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_projected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_projected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_bis' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPAVRxo_J4lu"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJO7a0FkKNlm"
      },
      "source": [
        "### Random Forest Classification (RFC)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB8q2bPyKA4j"
      },
      "source": [
        "RFC = make_pipeline(transformer,RandomForestClassifier(n_estimators=100))\r\n",
        "RFC.fit(X_train,Y_train)\r\n",
        "y_pred_rfc = RFC.predict(X_test)\r\n",
        "y_true_ = Y_test.ravel()\r\n",
        "\r\n",
        "recall_res_rfc = recall_score(y_true_, y_pred_rfc, average=None)\r\n",
        "precision_res_rfc = precision_score(y_true_, y_pred_rfc, average=None)\r\n",
        "f1score_res_rfc = f1_score(y_true_, y_pred_rfc, average=None)\r\n",
        "acc_res_rfc = accuracy_score(y_true_, y_pred_rfc)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KizlAf1Kq0X"
      },
      "source": [
        "### Support Vector Machine Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iidJneRzK3gG"
      },
      "source": [
        "SVC = make_pipeline(transformer,svm.SVC(kernel='rbf', C=1))\r\n",
        "SVC.fit(X_train,Y_train)\r\n",
        "y_pred_svc = SVC.predict(X_test)\r\n",
        "y_true_ = Y_test.ravel()\r\n",
        "\r\n",
        "recall_res_svc = recall_score(y_true_, y_pred_svc, average=None)\r\n",
        "precision_res_svc = precision_score(y_true_, y_pred_svc, average=None)\r\n",
        "f1score_res_svc = f1_score(y_true_, y_pred_svc, average=None)\r\n",
        "acc_res_svc = accuracy_score(y_true_, y_pred_svc)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR-_8W3oKsWf"
      },
      "source": [
        "### XBOOST Regressor Classifier (XGBC)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "d_96y8-rK_Fa",
        "outputId": "d5094be1-789a-4c43-e9f7-ec38cea6d86a"
      },
      "source": [
        "XGBC = make_pipeline(transformer,xgb.XGBClassifier(n_estimators=100))\r\n",
        "XGBC.fit(X_train, Y_train)\r\n",
        "y_pred_xgbc = XGBC.predict(X_test)\r\n",
        "y_true_ = Y_test.ravel()\r\n",
        "\r\n",
        "recall_res_xgbc = recall_score(y_true_, y_pred_xgbc, average=None)\r\n",
        "precision_res_xgbc = precision_score(y_true_, y_pred_xgbc, average=None)\r\n",
        "f1score_res_xgbc = f1_score(y_true_, y_pred_xgbc, average=None)\r\n",
        "acc_res_xgbc = accuracy_score(y_true_, y_pred_xgbc)\r\n",
        "\r\n",
        "confusion_mat_xgbc = confusion_matrix(y_true_, y_pred_xgbc)\r\n",
        "fig, ax = plt.subplots()\r\n",
        "sns.heatmap(data=confusion_mat_xgbc, annot=True, fmt='d', cmap=\"YlGnBu\",\r\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .70})\r\n",
        "ax.set_ylim(len(encodeur.classes_),0)\r\n",
        "ax.set_title('Confusion matrix of XGBC (n_estimators = 100)')\r\n",
        "ax.tick_params(axis='both',pad=15)\r\n",
        "ax.set_xlabel('Predicted')\r\n",
        "ax.set_xticklabels(encodeur.classes_,fontdict = {'horizontalalignment': 'center'},rotation=90)\r\n",
        "ax.set_ylabel('Actually')\r\n",
        "ax.set_yticklabels(encodeur.classes_,fontdict = {'verticalalignment': 'center'},rotation=360)\r\n",
        "\r\n",
        "result = permutation_importance(XGBC, X_test, Y_test, n_repeats=10,random_state=42, n_jobs=-1)\r\n",
        "sorted_idx = result.importances_mean.argsort()\r\n",
        "fig, ax = plt.subplots()\r\n",
        "ax.boxplot(result.importances[sorted_idx].T,vert=False, labels=X_test.columns[sorted_idx])\r\n",
        "ax.set_title(\"Permutation Importances XGBC(test set)\")\r\n",
        "fig.tight_layout()\r\n",
        "plt.show()\r\n",
        "\r\n",
        "prob = XGBC.predict_proba(X_test)\r\n",
        "fig, ax = plt.subplots(1,1)\r\n",
        "rep = (y_true_-y_pred_xgbc)\r\n",
        "l = np.array([i for i,x in enumerate(rep) if x!=0])\r\n",
        "sns.distplot(prob[l].max(axis=1))\r\n",
        "sns.distplot(prob[~l].max(axis=1))\r\n",
        "\r\n",
        "fig, ax = plt.subplots(figsize=(30, 30))\r\n",
        "xgb.plot_tree(XGBC['xgbclassifier'], num_trees=4, ax=ax)\r\n",
        "plt.show()\r\n",
        "\r\n",
        "file_name = \"xgb_cla_fsall.pkl\"\r\n",
        "# save\r\n",
        "pickle.dump(XGBC, open(file_name, \"wb\"))\r\n",
        "# load\r\n",
        "XGBC = pickle.load(open(file_name, \"rb\"))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-ac8f0e19b3b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mXGBC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mXGBC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred_xgbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_true_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1AfKnuTLJC7"
      },
      "source": [
        "### KNeighbors Classifier (KNC)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUDvH_G_LVF3"
      },
      "source": [
        "KNC = make_pipeline(transformer,KNeighborsClassifier(n_neighbors=10))\r\n",
        "KNC.fit(X_train, Y_train)\r\n",
        "y_pred_knc = KNC.predict(X_test)\r\n",
        "y_true_ = Y_test.ravel()\r\n",
        "\r\n",
        "recall_res_knc = recall_score(y_true_, y_pred_knc, average=None)\r\n",
        "precision_res_knc = precision_score(y_true_, y_pred_knc, average=None)\r\n",
        "f1score_res_knc = f1_score(y_true_, y_pred_knc, average=None)\r\n",
        "acc_res_knc = accuracy_score(y_true_, y_pred_knc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qszkmbruLYQ0"
      },
      "source": [
        "### Logistic Regression (LR)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaXTZRPxLmoJ"
      },
      "source": [
        "LR = make_pipeline(transformer,LogisticRegression())\r\n",
        "LR.fit(X_train, Y_train)\r\n",
        "y_pred_lr = LR.predict(X_test)\r\n",
        "y_true_ = Y_test.ravel()\r\n",
        "\r\n",
        "recall_res_lr = recall_score(y_true_, y_pred_lr, average=None)\r\n",
        "precision_res_lr = precision_score(y_true_, y_pred_lr, average=None)\r\n",
        "f1score_res_lr = f1_score(y_true_, y_pred_lr, average=None)\r\n",
        "acc_res_lr = accuracy_score(y_true_, y_pred_lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "futSJE1iLzO_"
      },
      "source": [
        "# Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSrGCdC-Lx75"
      },
      "source": [
        "# # compare ensemble to each baseline classifier\r\n",
        "# from numpy import mean\r\n",
        "# from numpy import std\r\n",
        "# from sklearn.datasets import make_classification\r\n",
        "# from sklearn.model_selection import cross_val_score\r\n",
        "# from sklearn.model_selection import RepeatedStratifiedKFold\r\n",
        "# from sklearn.linear_model import LogisticRegression\r\n",
        "# from sklearn.neighbors import KNeighborsClassifier\r\n",
        "# from sklearn.tree import DecisionTreeClassifier\r\n",
        "# from sklearn.svm import SVC\r\n",
        "# from sklearn.naive_bayes import GaussianNB\r\n",
        "# from sklearn.ensemble import StackingClassifier\r\n",
        "# from matplotlib import pyplot\r\n",
        "#\r\n",
        "# # get the dataset\r\n",
        "# def get_dataset():\r\n",
        "# \tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\r\n",
        "# \treturn X, y\r\n",
        "#\r\n",
        "# # get a stacking ensemble of models\r\n",
        "# def get_stacking():\r\n",
        "# \t# define the base models\r\n",
        "# \tlevel0 = list()\r\n",
        "# \tlevel0.append(('lr', LogisticRegression()))\r\n",
        "# \tlevel0.append(('knn', KNeighborsClassifier()))\r\n",
        "# \tlevel0.append(('cart', DecisionTreeClassifier()))\r\n",
        "# \tlevel0.append(('svm', SVC()))\r\n",
        "# \tlevel0.append(('bayes', GaussianNB()))\r\n",
        "# \t# define meta learner model\r\n",
        "# \tlevel1 = LogisticRegression()\r\n",
        "# \t# define the stacking ensemble\r\n",
        "# \tmodel = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\r\n",
        "# \treturn model\r\n",
        "#\r\n",
        "# # get a list of models to evaluate\r\n",
        "# def get_models():\r\n",
        "# \tmodels = dict()\r\n",
        "# \tmodels['lr'] = LogisticRegression()\r\n",
        "# \tmodels['knn'] = KNeighborsClassifier()\r\n",
        "# \tmodels['cart'] = DecisionTreeClassifier()\r\n",
        "# \tmodels['svm'] = SVC()\r\n",
        "# \tmodels['bayes'] = GaussianNB()\r\n",
        "# \tmodels['stacking'] = get_stacking()\r\n",
        "# \treturn models\r\n",
        "#\r\n",
        "# # evaluate a give model using cross-validation\r\n",
        "# def evaluate_model(model, X, y):\r\n",
        "# \tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\r\n",
        "# \tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\r\n",
        "# \treturn scores\r\n",
        "#\r\n",
        "# # define dataset\r\n",
        "# X, y = get_dataset()\r\n",
        "# # get the models to evaluate\r\n",
        "# models = get_models()\r\n",
        "# # evaluate the models and store results\r\n",
        "# results, names = list(), list()\r\n",
        "# for name, model in models.items():\r\n",
        "# \tscores = evaluate_model(model, X, y)\r\n",
        "# \tresults.append(scores)\r\n",
        "# \tnames.append(name)\r\n",
        "# \tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\r\n",
        "# # plot model performance for comparison\r\n",
        "# pyplot.boxplot(results, labels=names, showmeans=True)\r\n",
        "# pyplot.show()\r\n",
        "#\r\n",
        "# # make a prediction with a stacking ensemble\r\n",
        "# from sklearn.datasets import make_classification\r\n",
        "# from sklearn.ensemble import StackingClassifier\r\n",
        "# from sklearn.linear_model import LogisticRegression\r\n",
        "# from sklearn.neighbors import KNeighborsClassifier\r\n",
        "# from sklearn.tree import DecisionTreeClassifier\r\n",
        "# from sklearn.svm import SVC\r\n",
        "# from sklearn.naive_bayes import GaussianNB\r\n",
        "# # define dataset\r\n",
        "# X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\r\n",
        "# # define the base models\r\n",
        "# level0 = list()\r\n",
        "# level0.append(('lr', LogisticRegression()))\r\n",
        "# level0.append(('knn', KNeighborsClassifier()))\r\n",
        "# level0.append(('cart', DecisionTreeClassifier()))\r\n",
        "# level0.append(('svm', SVC()))\r\n",
        "# level0.append(('bayes', GaussianNB()))\r\n",
        "# # define meta learner model\r\n",
        "# level1 = LogisticRegression()\r\n",
        "# # define the stacking ensemble\r\n",
        "# model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\r\n",
        "# # fit the model on all available data\r\n",
        "# model.fit(X, y)\r\n",
        "# # make a prediction for one example\r\n",
        "# data = [[2.47475454,0.40165523,1.68081787,2.88940715,0.91704519,-3.07950644,4.39961206,0.72464273,-4.86563631,-6.06338084,-1.22209949,-0.4699618,1.01222748,-0.6899355,-0.53000581,6.86966784,-3.27211075,-6.59044146,-2.21290585,-3.139579]]\r\n",
        "# yhat = model.predict(data)\r\n",
        "# print('Predicted Class: %d' % (yhat))\r\n",
        "\r\n",
        "###\r\n",
        "\r\n",
        "# model = make_pipeline(transformer,RandomForestClassifier())\r\n",
        "# param_grid = {'randomforestclassifier__n_estimators':np.arange(20,21)}\r\n",
        "# grid = GridSearchCV(model,param_grid,cv=5)\r\n",
        "# grid.fit(X_train,Y_train)\r\n",
        "# model = grid.best_estimator_\r\n",
        "# b = model.score(X_train,Y_train)\r\n",
        "# y_pred_ = model.predict(X_test)\r\n",
        "# y_true_ = Y_test.ravel()\r\n",
        "#\r\n",
        "# recall_res = recall_score(y_true_, y_pred_, average=None)\r\n",
        "# precision_res = precision_score(y_true_, y_pred_, average=None)\r\n",
        "# f1score_res = f1_score(y_true_, y_pred_, average=None)\r\n",
        "# acc_res = accuracy_score(y_true_, y_pred_)\r\n",
        "#\r\n",
        "# confusion_mat = confusion_matrix(y_true_, y_pred_)\r\n",
        "# fig, ax = plt.subplots()\r\n",
        "# sns.heatmap(data=confusion_mat, annot=True, fmt='d')\r\n",
        "# ax.set_ylim(2,0)\r\n",
        "# ax.set_title('Confusion matrix of XGBOOST')\r\n",
        "# ax.set_xticklabels(['Intervention','No intervention'])\r\n",
        "\r\n",
        "# plt.figure(figsize=(10,5))\r\n",
        "# plt.rcParams.update({'font.size': 12})\r\n",
        "# sns.distplot(y_true, label='True values')\r\n",
        "# sns.distplot(y_pred, label='Predictions')\r\n",
        "# plt.title('Distribution of the number of days')\r\n",
        "# plt.xlabel('Number of days', fontsize=12)\r\n",
        "# plt.legend()\r\n",
        "# plt.show()\r\n",
        "\r\n",
        "# fs = SelectKBest(score_func=f_regression, k='all')\r\n",
        "# fs.fit(X_train[numerical_features], Y_train)\r\n",
        "# X_train_fs = fs.transform(X_train)\r\n",
        "# X_test_fs = fs.transform(X_test)\r\n",
        "\r\n",
        "# rf = RandomForestRegressor(n_estimators = 100,\r\n",
        "#                            n_jobs = -1,\r\n",
        "#                            oob_score = True,\r\n",
        "#                            bootstrap = True,\r\n",
        "#                            random_state = 42)\r\n",
        "#\r\n",
        "# model = make_pipeline(transformer,rf)\r\n",
        "# model.fit(X_train,Y_train)\r\n",
        "#\r\n",
        "# print('\\nR^2 Training Score: {:.2f} \\nOOB Score: {:.2f} \\nR^2 Validation Score: {:.2f}'.format(model.score(X_train, Y_train),\r\n",
        "#                                                                                              model['randomforestregressor'].oob_score_,\r\n",
        "#                                                                                              model.score(X_test, Y_test)))\r\n",
        "#\r\n",
        "# feature_list = model['columntransformer'].transformers_[0][2] + list(model['columntransformer'].transformers_[1][1]['onehotencoder'].get_feature_names(categorical_features)) + [s+'_ant_dp' for s in model['columntransformer'].transformers_[2][1]['countvectorizer'].get_feature_names()] + [s+'_ant_das' for s in model['columntransformer'].transformers_[3][1]['countvectorizer'].get_feature_names()]+[s+'_dp' for s in model['columntransformer'].transformers_[4][1]['countvectorizer'].get_feature_names()]\r\n",
        "# importances = model['randomforestregressor'].feature_importances_\r\n",
        "# sns.barplot(x=feature_list, y=importances)\r\n",
        "# plt.title('Feature importance in random forest')\r\n",
        "# plt.xticks(rotation=90)\r\n",
        "# plt.tight_layout()\r\n",
        "#\r\n",
        "# from sklearn.inspection import permutation_importance\r\n",
        "# result = permutation_importance(model, X_test, Y_test, n_repeats=10,\r\n",
        "#                                 random_state=42, n_jobs=-1)\r\n",
        "# sorted_idx = result.importances_mean.argsort()\r\n",
        "#\r\n",
        "# fig, ax = plt.subplots()\r\n",
        "# ax.boxplot(result.importances[sorted_idx].T,\r\n",
        "#             vert=False, labels=X_test.columns[sorted_idx])\r\n",
        "# ax.set_title(\"Permutation Importances (test set)\")\r\n",
        "# fig.tight_layout()\r\n",
        "# plt.show()\r\n",
        "\r\n",
        "# Import tools needed for visualization\r\n",
        "# from sklearn import tree\r\n",
        "# feature_list = model['columntransformer'].transformers_[0][2] + list(model['columntransformer'].transformers_[1][1]['onehotencoder'].get_feature_names(categorical_features)) + model['columntransformer'].transformers_[2][1]['countvectorizer'].get_feature_names() + model['columntransformer'].transformers_[3][1]['countvectorizer'].get_feature_names()\r\n",
        "# tree_rf = model['randomforestregressor'].estimators_[5]\r\n",
        "# fig = plt.figure(figsize = (100,100))\r\n",
        "# tree.plot_tree(tree_rf,\r\n",
        "#                 feature_names = feature_list,\r\n",
        "#                 class_names=['los'],\r\n",
        "#                 max_depth = 3,\r\n",
        "#                 filled = True,\r\n",
        "#                 fontsize = 1);\r\n",
        "# fig.savefig('rf_individualtree.png')\r\n",
        "\r\n",
        "# model = make_pipeline(transformer,xgb.XGBClassifier(n_estimators=100))\r\n",
        "# model.fit(X_train, Y_train)\r\n",
        "# print(\"\\nXGBoost obtient un score de {}% sur les données d'entrainement.\".format(100*model.score(X_train, Y_train)))\r\n",
        "# print(\"XGBoost obtient un score de {}% sur les données de test.\".format(100*model.score(X_test,Y_test)))\r\n",
        "\r\n",
        "#\r\n",
        "# neigh = make_pipeline(transformer,KNeighborsRegressor(n_neighbors=50))\r\n",
        "# neigh.fit(X_train, Y_train)\r\n",
        "# print(\"\\nKNNR obtient un score de {}% sur les données d'entrainement.\".format(100*neigh.score(X_train, Y_train)))\r\n",
        "# print(\"KNNR obtient un score de {}% sur les données de test.\".format(100*neigh.score(X_test,Y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}